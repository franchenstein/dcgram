{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGraM Algorithm\n",
    "\n",
    "This notebook implements the D-Markov with Clustering and Graph Minimization (DCGraM) Algorithm. Its objective is to model a discrete dynamical system using a Probabilistic Finite State Machine (PFSA). \n",
    "\n",
    "Given a sequence *X* over the alphabet $\\Sigma$ of length *N* that is an output of the original dynamical system, DCGraM works by:\n",
    "\n",
    "1. Creating a D-Markov model for the original system for a given *D*;\n",
    "2. Using a clustering algorithm on the D-Markov model states in order to create an initial partition;\n",
    "3. Using a graph minimization algorithm to refine the initial partition until the final reduced PFSA is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "First, it is necessary to create the directories that store the working files for the current system. The first cell sets the system's name and the tag to be used in the current run. The following cell only has to be ran when creating modeling a new system.  A directory is then created with this tag and inside it subdirectories that contain the sequence, PFSA and result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import sequenceanalyzer as sa\n",
    "import dmarkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'ternary_even_shift'\n",
    "tag = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(name):\n",
    "    os.makedirs(name)\n",
    "    os.makedirs(name + '/sequences')\n",
    "    os.makedirs(name + '/pfsa')\n",
    "    os.makedirs(name + '/results')\n",
    "    os.makedirs(name + '/results/probabilities')\n",
    "    os.makedirs(name + '/results/probabilities/conditional')\n",
    "    os.makedirs(name + '/results/cond_entropies')\n",
    "    os.makedirs(name + '/results/kldivergences')\n",
    "    os.makedirs(name + '/results/autocorrelations')\n",
    "    os.makedirs(name + '/results/prob_distances')\n",
    "    os.makedirs(name + '/results/plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "The next cell initializes the parameters that are used throughout the code. They are listed as:\n",
    "\n",
    "  * `N`: The original sequence length *N*, which is also the length of the sequences that are going to be generated by the PFSA generated by DCGraM;\n",
    "  * `drange`: range of values of *D* for which D-Markov and DCGraM machines that will be generated;\n",
    "  * `a`: value up to which the autocorrelation is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000000\n",
    "drange = range(4,11)\n",
    "a = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Sequence Analysis\n",
    "\n",
    "Make sure that the original sequence of length `N` is stored in the correct directory and run the cell to load it to `X`. After this, run the cells corresponding to the computation of the subsequence probabilities and the conditional probabilites for the value `d_max`, which is the last value in `drange`. Additional results can also be computed in the respective cells (autocorrelation and conditional entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open original sequence from yaml file\n",
    "with open(name + '/sequences/original_len_' + str(N) + '_' + tag + '.yaml', 'r') as f:\n",
    "    X = yaml.load(f)\n",
    "    \n",
    "#Value up to which results are computed\n",
    "d_max = drange[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute subsequence probabilities of occurrence up to length d_max\n",
    "p, alphabet = sa.calc_probs(X, d_max)\n",
    "p.to_csv(name + '/results/probabilities/original_' + tag + '.csv')\n",
    "with open(name + '/alphabet.yaml', 'w') as f:\n",
    "    yaml.dump(alphabet, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If p has been previously computed, use this cell to load the values\n",
    "if not p:\n",
    "    p = pd.read_csv(name + '/results/probabilities/original_' + tag + '.csv')\n",
    "    with open(name + '/alphabet.yaml', 'r') as f:\n",
    "        alphabet = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute conditional probabilities of subsequences occurring after given each symbol of the alphabet\n",
    "#One of the two previous cells needs to be executed first.\n",
    "if p:\n",
    "    p_cond = sa.calc_cond_probs(p, alphabet, d_max) \n",
    "    p_cond.to_csv(name + '/results/probabilities/conditional/original_' + tag + '.csv')\n",
    "else:\n",
    "    print(\"Run a cell that either computes or opens the probabilities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If p_cond has been previously computed, use this cell to load the values\n",
    "if not p_cond:\n",
    "    p_cond = pd.read_csv(name + '/results/probabilities/conditional/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute conditional entropy\n",
    "if p and p_cond:\n",
    "    h = sa.calc_cond_entropy(p, p_cond, d_max)\n",
    "    h.to_csv(name + '/results/cond_entropies/original_' + tag + '.csv')\n",
    "else:\n",
    "    print(\"Run the conditional probabilities cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If p_cond has been previously computed, use this cell to load the values\n",
    "if not h:\n",
    "    h = pd.read_csv(name + '/results/cond_entropies/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute autocorrelation\n",
    "aut = sa.calc_autocorr(X, a)\n",
    "aut.to_csv(name + '/results/autocorrelations/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If aut has been previously computed, use this cell to load the values\n",
    "if not aut:\n",
    "    aut = pd.read_csv(name + '/results/autocorrelations/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D-Markov Machines\n",
    "\n",
    "The next step of DCGraM consists of generating D-Markov Machines for each value of *D* in `drange` defined above. The values of `p_cond` for each of these values is then needed, so it is necessary to compute it above. A D-Markov Machine is a PFSA with $|\\Sigma|^D$ states, each one labeled with one of the subsquences of length $D$. Given a state $\\omega = \\sigma_1\\sigma_2\\ldots\\sigma_D$, for each $\\sigma \\in \\Sigma$, it transitions to the state $\\sigma_2\\sigma_3\\ldots\\sigma_D\\sigma$ with probability $\\Pr(\\sigma|\\omega)$. This is done for all states in the D-Markov machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmark_machines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If the D-Markov machines have not been previously created, generate them with this cell\n",
    "for D in drange:\n",
    "    dmark_machines.append(dmarkov.create(p_cond, D))\n",
    "    dmark_machines[-1].to_csv(name + '/pfsa/dmarkov_D' + D + '_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On the other hand, if there already are D-Markov machines, load them with this cell\n",
    "if not dmark_machines:\n",
    "    for D in drange:\n",
    "        dmark_machines.append(pd.read_csv(name + '/pfsa/dmarkov_D' + D + '_' + tag + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-Markov Machine Analysis\n",
    "\n",
    "First of all, sequences should be generated from the D-Markov Machines. The same parameters computed in the analysis of the original sequence should be computed for the D-Markov Machines' sequences. Besides those parameters, the Kullback-Leibler Divergence and Distribution Distance between these sequences and the original sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmark_seqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate sequences:\n",
    "count = 0\n",
    "for machine in dmark_machines:\n",
    "    seq = machine.generate_sequence(N)\n",
    "    with open(name + '/sequences/dmarkov_D' + drange[count++] + '_' + tag + '.yaml', 'w') as f:\n",
    "        yaml.dump(seq, f)\n",
    "    dmark_seqs.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If the sequences have been previously generated, load them here:\n",
    "if not dmark_seqs:\n",
    "    for D in drange:\n",
    "        with open(name + '/sequences/dmarkov_D' + D + '_' + tag + '.yaml', 'w') as f:\n",
    "            dmark_seqs.append(yaml.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute subsequence probabilities of occurrence of the D-Markov sequences\n",
    "count = 0\n",
    "p_dmark = []\n",
    "for seq in dmark_seqs:\n",
    "    p_dm, alphabet = sa.calc_probs(seq, d_max)\n",
    "    p_dm.to_csv(name + '/results/probabilities/dmarkov_D'+ drange[count++]  + '_' + tag + '.csv')\n",
    "    p_dmark.append(p_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If p_dmark has been previously computed, use this cell to load the values\n",
    "if not p_dmark:\n",
    "    for D in drange:\n",
    "        p_dm = pd.read_csv(name + '/results/probabilities/dmarkov_D' + D + '_' + tag + '.csv')\n",
    "        p_dmark.append(p_dm)\n",
    "    with open(name + '/alphabet.yaml', 'r') as f:\n",
    "        alphabet = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute conditional probabilities of subsequences occurring after given each symbol of the alphabet\n",
    "#One of the two previous cells needs to be executed first.\n",
    "p_cond_dmark = None\n",
    "count = 0\n",
    "if p_dmark:\n",
    "    for p_dm in p_dmark:\n",
    "        p_cond_dm = sa.calc_cond_probs(p_dm, alphabet, d_max) \n",
    "        p_cond_dm.to_csv(name + '/results/probabilities/conditional/dmarkov_D' + drange[count++] + '_' + tag + '.csv')\n",
    "        p_cond_dmark.append(p_cond_dm)\n",
    "else:\n",
    "    print(\"Run a cell that either computes or opens the probabilities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If p_cond has been previously computed, use this cell to load the values\n",
    "if not p_cond:\n",
    "    p_cond = pd.read_csv(name + '/results/probabilities/conditional/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute conditional entropy\n",
    "if p and p_cond:\n",
    "    h = sa.calc_cond_entropy(p, p_cond, d_max)\n",
    "    h.to_csv(name + '/results/cond_entropies/original_' + tag + '.csv')\n",
    "else:\n",
    "    print(\"Run the conditional probabilities cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If p_cond has been previously computed, use this cell to load the values\n",
    "if not h:\n",
    "    h = pd.read_csv(name + '/results/cond_entropies/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute autocorrelation\n",
    "aut = sa.calc_autocorr(X, a)\n",
    "aut.to_csv(name + '/results/autocorrelations/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If aut has been previously computed, use this cell to load the values\n",
    "if not aut:\n",
    "    aut = pd.read_csv(name + '/results/autocorrelations/original_' + tag + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGraM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
